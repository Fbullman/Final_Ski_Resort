{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdYzxf3gCiI",
        "outputId": "de0494ca-4f1e-41b4-f849-a3649cc4865a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6d666Hg37n",
        "outputId": "536eb00b-eb31-4c12-bdcc-c30df70c5bf8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (109 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"PySpark_NLP\").getOrCreate()"
      ],
      "metadata": {
        "id": "43SszxYhhy4m"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/My Drive/Colab Notebooks/Resort_reviews_data_DRive\""
      ],
      "metadata": {
        "id": "8v7azdnUkCc0"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/drive/My Drive/Colab Notebooks/Resort_reviews_data_DRive/resort_rating_up.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "40QCM66cjkkL"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7xQJjzalXFm",
        "outputId": "0e33f8a6-dc2d-45f4-b229-6d052571d855"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+-----------+--------+-----------------------------+--------------------+\n",
            "|Review Site|            Ski Area|Review Date|   class|Review Star Rating (out of 5)|         Review Text|\n",
            "+-----------+--------------------+-----------+--------+-----------------------------+--------------------+\n",
            "|Tripadvisor|Whitefish Mountai...|     17-Jan|positive|                            5|I love Big Mounta...|\n",
            "|Tripadvisor|Whitefish Mountai...|     16-Dec|positive|                            5|We have come to W...|\n",
            "|Tripadvisor|Whitefish Mountai...|     16-Dec|positive|                            4|We took our famil...|\n",
            "|Tripadvisor|Whitefish Mountai...|     16-Dec|positive|                            4|We skied two days...|\n",
            "|Tripadvisor|Whitefish Mountai...|     16-Dec|positive|                            4|Very good skiing....|\n",
            "+-----------+--------------------+-----------+--------+-----------------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df = df[['class','Review Text']]"
      ],
      "metadata": {
        "id": "V3tohm8m9gQR"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPTE302L94DI",
        "outputId": "e3f88435-9b79-4178-f14f-dd49dfcce341"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|   class|         Review Text|\n",
            "+--------+--------------------+\n",
            "|positive|I love Big Mounta...|\n",
            "|positive|We have come to W...|\n",
            "|positive|We took our famil...|\n",
            "|positive|We skied two days...|\n",
            "|positive|Very good skiing....|\n",
            "|negative|Champagne pow can...|\n",
            "|positive|We were here the ...|\n",
            "|positive|Amazing ski resor...|\n",
            "|negative|We skied a couple...|\n",
            "|positive|Big Mountain aka ...|\n",
            "|negative|The breadth of sk...|\n",
            "|negative|Our family loves ...|\n",
            "|negative|Trying to get a b...|\n",
            "|positive|Big Mountain ... ...|\n",
            "|positive|Had another great...|\n",
            "|negative|I was not as impr...|\n",
            "|negative|Visited in June. ...|\n",
            "|negative|the big mountain ...|\n",
            "|positive|Many years ago I ...|\n",
            "|negative|My hubby and I dr...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "metadata": {
        "id": "RN3N4tq7mCxs"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature\n",
        "data_df = reviews_df.withColumn('length', length(reviews_df['Review Text']))\n",
        "data_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLqO51o4mPyU",
        "outputId": "0f7a3b34-5200-478f-a9e7-0ca885d9e93c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|         Review Text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|I love Big Mounta...|   242|\n",
            "|positive|We have come to W...|   279|\n",
            "|positive|We took our famil...|   280|\n",
            "|positive|We skied two days...|   230|\n",
            "|positive|Very good skiing....|   118|\n",
            "|negative|Champagne pow can...|   110|\n",
            "|positive|We were here the ...|   279|\n",
            "|positive|Amazing ski resor...|   215|\n",
            "|negative|We skied a couple...|   277|\n",
            "|positive|Big Mountain aka ...|   276|\n",
            "|negative|The breadth of sk...|   279|\n",
            "|negative|Our family loves ...|   223|\n",
            "|negative|Trying to get a b...|   282|\n",
            "|positive|Big Mountain ... ...|   226|\n",
            "|positive|Had another great...|   148|\n",
            "|negative|I was not as impr...|   279|\n",
            "|negative|Visited in June. ...|   277|\n",
            "|negative|the big mountain ...|   276|\n",
            "|positive|Many years ago I ...|   275|\n",
            "|negative|My hubby and I dr...|   191|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"Review Text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashing = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token', numFeatures=pow(2,18))\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "metadata": {
        "id": "Gb3t_7MFmtE0"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "metadata": {
        "id": "VuqT_-zHrdvI"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "metadata": {
        "id": "n-9MrSBzriCc"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "metadata": {
        "id": "TPZPNsa0s80D"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3WaCFvtIO05",
        "outputId": "c379390e-7d7f-4d3f-f5e5-85c1c9127821"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   class|         Review Text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|positive|I love Big Mounta...|   242|  0.0|[i, love, big, mo...|[love, big, mount...|(262144,[535,2182...|(262144,[535,2182...|(262145,[535,2182...|\n",
            "|positive|We have come to W...|   279|  0.0|[we, have, come, ...|[come, whitefish,...|(262144,[535,1240...|(262144,[535,1240...|(262145,[535,1240...|\n",
            "|positive|We took our famil...|   280|  0.0|[we, took, our, f...|[took, family, sk...|(262144,[329,2545...|(262144,[329,2545...|(262145,[329,2545...|\n",
            "|positive|We skied two days...|   230|  0.0|[we, skied, two, ...|[skied, two, days...|(262144,[15775,34...|(262144,[15775,34...|(262145,[15775,34...|\n",
            "|positive|Very good skiing....|   118|  0.0|[very, good, skii...|[good, skiing., c...|(262144,[83668,89...|(262144,[83668,89...|(262145,[83668,89...|\n",
            "|negative|Champagne pow can...|   110|  1.0|[champagne, pow, ...|[champagne, pow, ...|(262144,[6346,184...|(262144,[6346,184...|(262145,[6346,184...|\n",
            "|positive|We were here the ...|   279|  0.0|[we, were, here, ...|[third, week, mar...|(262144,[3928,463...|(262144,[3928,463...|(262145,[3928,463...|\n",
            "|positive|Amazing ski resor...|   215|  0.0|[amazing, ski, re...|[amazing, ski, re...|(262144,[20997,24...|(262144,[20997,24...|(262145,[20997,24...|\n",
            "|negative|We skied a couple...|   277|  1.0|[we, skied, a, co...|[skied, couple, d...|(262144,[4214,459...|(262144,[4214,459...|(262145,[4214,459...|\n",
            "|positive|Big Mountain aka ...|   276|  0.0|[big, mountain, a...|[big, mountain, a...|(262144,[535,1252...|(262144,[535,1252...|(262145,[535,1252...|\n",
            "|negative|The breadth of sk...|   279|  1.0|[the, breadth, of...|[breadth, skiing,...|(262144,[5381,315...|(262144,[5381,315...|(262145,[5381,315...|\n",
            "|negative|Our family loves ...|   223|  1.0|[our, family, lov...|[family, loves, w...|(262144,[535,1600...|(262144,[535,1600...|(262145,[535,1600...|\n",
            "|negative|Trying to get a b...|   282|  1.0|[trying, to, get,...|[trying, get, bre...|(262144,[535,1965...|(262144,[535,1965...|(262145,[535,1965...|\n",
            "|positive|Big Mountain ... ...|   226|  0.0|[big, mountain, ....|[big, mountain, ....|(262144,[535,1928...|(262144,[535,1928...|(262145,[535,1928...|\n",
            "|positive|Had another great...|   148|  0.0|[had, another, gr...|[another, great, ...|(262144,[35844,55...|(262144,[35844,55...|(262145,[35844,55...|\n",
            "|negative|I was not as impr...|   279|  1.0|[i, was, not, as,...|[impressed, resor...|(262144,[7625,912...|(262144,[7625,912...|(262145,[7625,912...|\n",
            "|negative|Visited in June. ...|   277|  1.0|[visited, in, jun...|[visited, june., ...|(262144,[16487,22...|(262144,[16487,22...|(262145,[16487,22...|\n",
            "|negative|the big mountain ...|   276|  1.0|[the, big, mounta...|[big, mountain, g...|(262144,[535,2234...|(262144,[535,2234...|(262145,[535,2234...|\n",
            "|positive|Many years ago I ...|   275|  0.0|[many, years, ago...|[many, years, ago...|(262144,[8804,425...|(262144,[8804,425...|(262145,[8804,425...|\n",
            "|negative|My hubby and I dr...|   191|  1.0|[my, hubby, and, ...|[hubby, drove, lo...|(262144,[20637,20...|(262144,[20637,20...|(262145,[20637,20...|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3], 21)"
      ],
      "metadata": {
        "id": "paN0LSDNIT2h"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "CHlfKoWsIW8X"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oE9YUVUI6-2",
        "outputId": "e5d0bdf2-ed03-4477-e411-76afb00a09eb"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|         Review Text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|\"If you're going ...|   211|  1.0|[\"if, you're, goi...|[\"if, going, comp...|(262144,[12336,14...|(262144,[12336,14...|(262145,[12336,14...|[-1212.5704605873...|[1.0,7.9227746967...|       0.0|\n",
            "|negative|\"So this part of ...|   203|  1.0|[\"so, this, part,...|[\"so, part, count...|(262144,[8804,105...|(262144,[8804,105...|(262145,[8804,105...|[-1287.6725062614...|[1.0,1.7990717646...|       0.0|\n",
            "|negative|14 inches of new ...|   201|  1.0|[14, inches, of, ...|[14, inches, new,...|(262144,[2437,125...|(262144,[2437,125...|(262145,[2437,125...|[-1066.8695681678...|[1.0,1.5324343060...|       0.0|\n",
            "|negative|After purchasing ...|   198|  1.0|[after, purchasin...|[purchasing, two,...|(262144,[16928,20...|(262144,[16928,20...|(262145,[16928,20...|[-1180.7668086201...|[1.0,1.1962900227...|       0.0|\n",
            "|negative|Best spring skiin...|   111|  1.0|[best, spring, sk...|[best, spring, sk...|(262144,[3968,786...|(262144,[3968,786...|(262145,[3968,786...|[-671.15537908407...|[1.0,3.0929686930...|       0.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "acc_eval = BinaryClassificationEvaluator(labelCol ='label', rawPredictionCol =\"prediction\")\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CmK3Yf9I_Dh",
        "outputId": "c31d6697-1580-4c61-e551-10fa46bff095"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.500000\n"
          ]
        }
      ]
    }
  ]
}