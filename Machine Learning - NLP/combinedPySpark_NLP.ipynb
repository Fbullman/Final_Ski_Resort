{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combinedPySpark_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIdYzxf3gCiI",
        "outputId": "08f23a53-decc-45d1-ccb7-70597f471904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.3'\n",
        "spark_version = 'spark-3.0.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NI6d666Hg37n",
        "outputId": "4b4c0cb7-524c-4728-e611-14b9959f447c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 4,096 B/88.7\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 3s (98.4 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"PySpark_NLP\").getOrCreate()"
      ],
      "metadata": {
        "id": "43SszxYhhy4m"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/My Drive/Colab Notebooks/Resort_reviews_data_DRive\""
      ],
      "metadata": {
        "id": "8v7azdnUkCc0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/drive/My Drive/Colab Notebooks/Resort_reviews_data_DRive/compiled_reviews_up.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "40QCM66cjkkL"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7xQJjzalXFm",
        "outputId": "b113b565-f59b-4666-c020-4b6a564051e7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+-----------+--------+-----------------------------+--------------------+\n",
            "|Review Site| Ski Area|Review Date|   class|Review Star Rating (out of 5)|         Review Text|\n",
            "+-----------+---------+-----------+--------+-----------------------------+--------------------+\n",
            "|Tripadvisor|Whitefish|     17-Jan|positive|                            5|I love Big Mounta...|\n",
            "|Tripadvisor|Whitefish|     16-Dec|positive|                            5|We have come to W...|\n",
            "|Tripadvisor|Whitefish|     16-Dec|positive|                            4|We took our famil...|\n",
            "|Tripadvisor|Whitefish|     16-Dec|positive|                            4|We skied two days...|\n",
            "|Tripadvisor|Whitefish|     16-Dec|positive|                            4|Very good skiing....|\n",
            "+-----------+---------+-----------+--------+-----------------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df = df[['class','Review Text']]"
      ],
      "metadata": {
        "id": "V3tohm8m9gQR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPTE302L94DI",
        "outputId": "90a59dfb-088f-4170-c50f-f6fb6fd49e5d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|   class|         Review Text|\n",
            "+--------+--------------------+\n",
            "|positive|I love Big Mounta...|\n",
            "|positive|We have come to W...|\n",
            "|positive|We took our famil...|\n",
            "|positive|We skied two days...|\n",
            "|positive|Very good skiing....|\n",
            "|negative|Champagne pow can...|\n",
            "|positive|We were here the ...|\n",
            "|positive|Amazing ski resor...|\n",
            "|negative|We skied a couple...|\n",
            "|positive|Big Mountain aka ...|\n",
            "|negative|The breadth of sk...|\n",
            "|negative|Our family loves ...|\n",
            "|negative|Trying to get a b...|\n",
            "|positive|Big Mountain ... ...|\n",
            "|positive|Had another great...|\n",
            "|negative|I was not as impr...|\n",
            "|negative|Visited in June. ...|\n",
            "|negative|the big mountain ...|\n",
            "|positive|Many years ago I ...|\n",
            "|negative|My hubby and I dr...|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "metadata": {
        "id": "RN3N4tq7mCxs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature\n",
        "data_df = reviews_df.withColumn('length', length(reviews_df['Review Text']))\n",
        "data_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLqO51o4mPyU",
        "outputId": "56e9b18b-ad0d-42b6-ded5-79ff3e5cfa2c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|         Review Text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|I love Big Mounta...|   242|\n",
            "|positive|We have come to W...|   279|\n",
            "|positive|We took our famil...|   280|\n",
            "|positive|We skied two days...|   230|\n",
            "|positive|Very good skiing....|   118|\n",
            "|negative|Champagne pow can...|   110|\n",
            "|positive|We were here the ...|   279|\n",
            "|positive|Amazing ski resor...|   215|\n",
            "|negative|We skied a couple...|   277|\n",
            "|positive|Big Mountain aka ...|   276|\n",
            "|negative|The breadth of sk...|   279|\n",
            "|negative|Our family loves ...|   223|\n",
            "|negative|Trying to get a b...|   282|\n",
            "|positive|Big Mountain ... ...|   226|\n",
            "|positive|Had another great...|   148|\n",
            "|negative|I was not as impr...|   279|\n",
            "|negative|Visited in June. ...|   277|\n",
            "|negative|the big mountain ...|   276|\n",
            "|positive|Many years ago I ...|   275|\n",
            "|negative|My hubby and I dr...|   191|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "up_data_df = data_df.dropna()"
      ],
      "metadata": {
        "id": "zJIeUDZVQlPm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"Review Text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashing = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "metadata": {
        "id": "Gb3t_7MFmtE0"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "metadata": {
        "id": "VuqT_-zHrdvI"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashing, idf, clean_up])"
      ],
      "metadata": {
        "id": "n-9MrSBzriCc"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(up_data_df)\n",
        "cleaned = cleaner.transform(up_data_df)"
      ],
      "metadata": {
        "id": "TPZPNsa0s80D"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3WaCFvtIO05",
        "outputId": "80d8809d-a8ba-46d9-e4e5-22af184f0f3a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   class|         Review Text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|positive|I love Big Mounta...|   242|  0.0|[i, love, big, mo...|[love, big, mount...|(262144,[535,2182...|(262144,[535,2182...|(262145,[535,2182...|\n",
            "|positive|We have come to W...|   279|  0.0|[we, have, come, ...|[come, whitefish,...|(262144,[535,1240...|(262144,[535,1240...|(262145,[535,1240...|\n",
            "|positive|We took our famil...|   280|  0.0|[we, took, our, f...|[took, family, sk...|(262144,[329,2545...|(262144,[329,2545...|(262145,[329,2545...|\n",
            "|positive|We skied two days...|   230|  0.0|[we, skied, two, ...|[skied, two, days...|(262144,[15775,34...|(262144,[15775,34...|(262145,[15775,34...|\n",
            "|positive|Very good skiing....|   118|  0.0|[very, good, skii...|[good, skiing., c...|(262144,[83668,89...|(262144,[83668,89...|(262145,[83668,89...|\n",
            "|negative|Champagne pow can...|   110|  1.0|[champagne, pow, ...|[champagne, pow, ...|(262144,[6346,184...|(262144,[6346,184...|(262145,[6346,184...|\n",
            "|positive|We were here the ...|   279|  0.0|[we, were, here, ...|[third, week, mar...|(262144,[3928,463...|(262144,[3928,463...|(262145,[3928,463...|\n",
            "|positive|Amazing ski resor...|   215|  0.0|[amazing, ski, re...|[amazing, ski, re...|(262144,[20997,24...|(262144,[20997,24...|(262145,[20997,24...|\n",
            "|negative|We skied a couple...|   277|  1.0|[we, skied, a, co...|[skied, couple, d...|(262144,[4214,459...|(262144,[4214,459...|(262145,[4214,459...|\n",
            "|positive|Big Mountain aka ...|   276|  0.0|[big, mountain, a...|[big, mountain, a...|(262144,[535,1252...|(262144,[535,1252...|(262145,[535,1252...|\n",
            "|negative|The breadth of sk...|   279|  1.0|[the, breadth, of...|[breadth, skiing,...|(262144,[5381,315...|(262144,[5381,315...|(262145,[5381,315...|\n",
            "|negative|Our family loves ...|   223|  1.0|[our, family, lov...|[family, loves, w...|(262144,[535,1600...|(262144,[535,1600...|(262145,[535,1600...|\n",
            "|negative|Trying to get a b...|   282|  1.0|[trying, to, get,...|[trying, get, bre...|(262144,[535,1965...|(262144,[535,1965...|(262145,[535,1965...|\n",
            "|positive|Big Mountain ... ...|   226|  0.0|[big, mountain, ....|[big, mountain, ....|(262144,[535,1928...|(262144,[535,1928...|(262145,[535,1928...|\n",
            "|positive|Had another great...|   148|  0.0|[had, another, gr...|[another, great, ...|(262144,[35844,55...|(262144,[35844,55...|(262145,[35844,55...|\n",
            "|negative|I was not as impr...|   279|  1.0|[i, was, not, as,...|[impressed, resor...|(262144,[7625,912...|(262144,[7625,912...|(262145,[7625,912...|\n",
            "|negative|Visited in June. ...|   277|  1.0|[visited, in, jun...|[visited, june., ...|(262144,[16487,22...|(262144,[16487,22...|(262145,[16487,22...|\n",
            "|negative|the big mountain ...|   276|  1.0|[the, big, mounta...|[big, mountain, g...|(262144,[535,2234...|(262144,[535,2234...|(262145,[535,2234...|\n",
            "|positive|Many years ago I ...|   275|  0.0|[many, years, ago...|[many, years, ago...|(262144,[8804,425...|(262144,[8804,425...|(262145,[8804,425...|\n",
            "|negative|My hubby and I dr...|   191|  1.0|[my, hubby, and, ...|[hubby, drove, lo...|(262144,[20637,20...|(262144,[20637,20...|(262145,[20637,20...|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3], 21)"
      ],
      "metadata": {
        "id": "paN0LSDNIT2h"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "metadata": {
        "id": "CHlfKoWsIW8X"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oE9YUVUI6-2",
        "outputId": "0094f157-8824-4b6d-c1a2-c5859dc68ee7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|               class|         Review Text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| and if you're co...| there are a seve...|    75|  6.0|[, there, are, a,...|[, several, bette...|(262144,[23120,40...|(262144,[23120,40...|(262145,[23120,40...|[-425.56027097701...|[1.0,1.6084660621...|       0.0|\n",
            "| but it wound up ...| which helped her...|   105| 13.0|[, which, helped,...|[, helped, lot., ...|(262144,[150,1252...|(262144,[150,1252...|(262145,[150,1252...|[-425.96932044472...|[1.0,7.1524339636...|       0.0|\n",
            "| really knows his...|        great locals|    13| 23.0|   [, great, locals]|   [, great, locals]|(262144,[188205,2...|(262144,[188205,2...|(262145,[188205,2...|[-62.756800898718...|[0.99999983915154...|       0.0|\n",
            "| the challenging ...|                slow|     5| 29.0|            [, slow]|            [, slow]|(262144,[27707,24...|(262144,[27707,24...|(262145,[27707,24...|[-57.846846908377...|[0.99870973081012...|       0.0|\n",
            "|            negative|\"First off, this ...|   276|  1.0|[\"first, off,, th...|[\"first, off,, aw...|(262144,[535,1342...|(262144,[535,1342...|(262145,[535,1342...|[-1569.0118822907...|[1.0,9.1222404204...|       0.0|\n",
            "+--------------------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "acc_eval = BinaryClassificationEvaluator(labelCol ='label', rawPredictionCol =\"prediction\")\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CmK3Yf9I_Dh",
        "outputId": "b7ba5445-bf2d-4bfb-b465-a0f5aa86d010"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of model at predicting reviews was: 0.500000\n"
          ]
        }
      ]
    }
  ]
}